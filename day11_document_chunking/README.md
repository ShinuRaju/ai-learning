# Day 11: Document Chunking

## ðŸŽ¯ Learning Goals

- Understand document chunking strategies for RAG systems
- Learn about chunk size vs context trade-offs
- Implement multiple splitting strategies
- Prepare documents for embedding and vector storage
- Compare chunking approaches for different content types

## ðŸ“š Concepts Covered

### Why Chunking Matters

1. **LLM Context Limits**: Most models have token limits (4K-128K)
2. **Retrieval Efficiency**: Focused chunks improve search relevance
3. **Embedding Quality**: Optimal chunk size enhances semantic understanding
4. **Memory Management**: Smaller chunks are easier to process

### Chunking Strategies

#### 1. Recursive Character Splitter

- **Best for**: General-purpose text splitting
- **How it works**: Tries to split on paragraphs, then sentences, then words
- **Separators**: `["\n\n", "\n", ". ", " ", ""]`

#### 2. Character Splitter

- **Best for**: Predictable, consistent chunk sizes
- **How it works**: Splits on specific character sequences
- **Use case**: When you need uniform chunk lengths

#### 3. Token Splitter

- **Best for**: Precise LLM token management
- **How it works**: Counts actual tokens, not characters
- **Use case**: When staying within exact token limits

#### 4. Content-Aware Splitters

- **Markdown Splitter**: Respects markdown structure
- **Code Splitter**: Preserves function/class boundaries
- **Use case**: Maintaining semantic coherence

### Optimization Parameters

#### Chunk Size

- **Small (200-500 tokens)**: Better for embedding similarity
- **Medium (500-1000 tokens)**: Good balance for retrieval
- **Large (1000+ tokens)**: More context but less precise

#### Chunk Overlap

- **No Overlap (0%)**: Clean separation, no redundancy
- **Low Overlap (10-20%)**: Preserves some context
- **High Overlap (30%+)**: Better continuity, more storage

## ðŸ”§ Implementation

### Core Components

1. **DocumentChunker**: Main chunking engine
2. **Multiple Splitters**: Different strategies for different content
3. **Analysis Tools**: Evaluate chunk quality and distribution
4. **Interactive Interface**: Test different strategies

### Sample Documents

- **Technical Article**: AI/ML content with headings and sections
- **Financial Report**: Structured business document
- **Code Documentation**: Mixed text and code content

## ðŸŽ® Usage Examples

```python
# Initialize chunker
chunker = DocumentChunker()

# Load document
doc = chunker.load_document_from_text(text, metadata)

# Try different strategies
chunks_recursive = chunker.chunk_document(doc, "recursive")
chunks_character = chunker.chunk_document(doc, "character")

# Analyze results
analysis = chunker.analyze_chunks(chunks_recursive)
comparison = chunker.compare_strategies(doc)
```

## ðŸš€ Running the Demo

```bash
python document_chunker.py
```

### Interactive Commands

- `sample technical` - Load technical article sample
- `sample financial` - Load financial report sample
- `sample code` - Load code documentation sample
- `text <your_text>` - Process custom text
- `chunk recursive` - Chunk with recursive splitter
- `chunk character` - Chunk with character splitter
- `analyze` - Show chunk statistics
- `compare` - Compare all strategies
- `demo` - Run full demonstrations

## ðŸ“Š What You'll Learn

### Chunking Trade-offs

1. **Size vs Precision**: Larger chunks = more context, less precise retrieval
2. **Overlap vs Storage**: More overlap = better continuity, more data
3. **Speed vs Quality**: Simple splitting = faster, content-aware = better

### Content-Specific Strategies

- **Articles**: Recursive splitter with paragraph boundaries
- **Code**: Code-aware splitter preserving function structure
- **Reports**: Character splitter for consistent sections
- **Mixed Content**: Hybrid approaches

### Preparation for RAG

- Optimal chunk sizes for different embedding models
- Metadata preservation for filtering and routing
- Quality metrics for chunk evaluation
- Integration patterns for vector storage

## ðŸ”„ Next Steps (Day 12-15)

- **Day 12**: Embeddings - Converting chunks to vectors
- **Day 13**: Vector Search - Finding relevant chunks
- **Day 14**: RAG Pipeline - Combining retrieval with generation
- **Day 15**: RAG Evaluation - Measuring system performance

## ðŸ’¡ Key Takeaways

1. **No One-Size-Fits-All**: Different content needs different strategies
2. **Quality over Quantity**: Better chunks improve retrieval performance
3. **Test and Measure**: Evaluate strategies on your specific content
4. **Context Preservation**: Balance chunk size with semantic coherence
5. **Prepare for Embedding**: Consider downstream processing requirements

Start with the `demo` command to see all strategies in action! ðŸš€
